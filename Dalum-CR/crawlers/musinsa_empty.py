from playwright.sync_api import sync_playwright, TimeoutError as PlaywrightTimeoutError, Error as PlaywrightError
from urllib.parse import urlsplit, urlunsplit, parse_qs, urlencode
import csv
import time
import os

# ===============================
# ê²½ë¡œ ì„¤ì •
# ===============================
BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
OUTPUT_DIR = os.path.join(BASE_DIR, "output", "musinsa-empty")

MAX_PAGES_PER_CATEGORY = 200
NO_NEW_PAGES_LIMIT = 3
REPEAT_PAGE_LIMIT = 2
ROUND_UNIT_WON = 10
BASE_URL = "https://empty.seoul.kr"

CATEGORIES = {
    #OUTER
    "ìˆ íŒ¨ë”©": "https://empty.seoul.kr/product/list.html?cate_no=109",
    "ì½”íŠ¸": "https://empty.seoul.kr/product/list.html?cate_no=93",
    "ë ˆë” ìì¼“": "https://empty.seoul.kr/product/list.html?cate_no=90",
    "ë¬´ìŠ¤íƒ•/í¼": "https://empty.seoul.kr/product/list.html?cate_no=148",
    #TOP
    "í‹°ì…”ì¸ ": "https://empty.seoul.kr/product/list.html?cate_no=54",
    "ê¸´ì†Œë§¤ ì…”ì¸ ": "https://empty.seoul.kr/product/list.html?cate_no=101", 
    "ìŠ¤ì›¨íŠ¸ ì…”ì¸ ": "https://empty.seoul.kr/product/list.html?cate_no=77",
    "í›„ë“œ": "https://empty.seoul.kr/product/list.html?cate_no=64",
    "í”Œë¦¬ìŠ¤": "https://empty.seoul.kr/product/list.html?cate_no=822",
    #BOTTOM
    "ë°ë‹˜ íŒ¬ì¸ ": "https://empty.seoul.kr/product/list.html?cate_no=61",
    "íŒ¬ì¸ ": "https://empty.seoul.kr/product/list.html?cate_no=75",
    "ìŠ¤ì»¤íŠ¸": "https://empty.seoul.kr/product/list.html?cate_no=95",
    #DRESS
    "ì›í”¼ìŠ¤": "https://empty.seoul.kr/product/list.html?cate_no=59",
    #BAG
    "ë°±íŒ©": "https://empty.seoul.kr/product/list.html?cate_no=98",
    "í† íŠ¸ë°±": "https://empty.seoul.kr/product/list.html?cate_no=88",
    "í¬ë¡œìŠ¤ë°±": "https://empty.seoul.kr/product/list.html?cate_no=99",
    #SHOES
    "ìŠ¤ë‹ˆì»¤ì¦ˆ": "https://empty.seoul.kr/product/list.html?cate_no=113",
    "ë¶€ì¸ ": "https://empty.seoul.kr/product/list.html?cate_no=67",
    #HAT
    "ìº¡ëª¨ì": "https://empty.seoul.kr/product/list.html?cate_no=324",
    "ë¹„ë‹ˆ": "https://empty.seoul.kr/product/list.html?cate_no=341"
}

CATEGORY_MAP = {
    #OUTER
    "ìˆ íŒ¨ë”©": {"ëŒ€ë¶„ë¥˜": "OUTER", "ì¤‘ë¶„ë¥˜": "PADDING"},
    "ì½”íŠ¸": {"ëŒ€ë¶„ë¥˜": "OUTER", "ì¤‘ë¶„ë¥˜": "COAT"},
    "ë ˆë” ìì¼“": {"ëŒ€ë¶„ë¥˜": "OUTER", "ì¤‘ë¶„ë¥˜": "JACKET"},
    "ë¬´ìŠ¤íƒ•/í¼": {"ëŒ€ë¶„ë¥˜": "OUTER", "ì¤‘ë¶„ë¥˜": "JACKET"},
    #TOP
    "í‹°ì…”ì¸ ": {"ëŒ€ë¶„ë¥˜": "TOP", "ì¤‘ë¶„ë¥˜": "TSHIRT"},
    "ê¸´ì†Œë§¤ ì…”ì¸ ": {"ëŒ€ë¶„ë¥˜": "TOP", "ì¤‘ë¶„ë¥˜": "LSHIRT"},
    "ìŠ¤ì›¨íŠ¸ ì…”ì¸ ": {"ëŒ€ë¶„ë¥˜": "TOP", "ì¤‘ë¶„ë¥˜": "SWEATSHIRT"},
    "í›„ë“œ": {"ëŒ€ë¶„ë¥˜": "TOP", "ì¤‘ë¶„ë¥˜": "HOODIE"},
    "í”Œë¦¬ìŠ¤": {"ëŒ€ë¶„ë¥˜": "TOP", "ì¤‘ë¶„ë¥˜": "FLEECE"},
    #BOTTOM
    "ë°ë‹˜ íŒ¬ì¸ ": {"ëŒ€ë¶„ë¥˜": "BOTTOM", "ì¤‘ë¶„ë¥˜": "DENIM"},
    "íŒ¬ì¸ ": {"ëŒ€ë¶„ë¥˜": "BOTTOM", "ì¤‘ë¶„ë¥˜": "PANTS"},
    "ìŠ¤ì»¤íŠ¸": {"ëŒ€ë¶„ë¥˜": "BOTTOM", "ì¤‘ë¶„ë¥˜": "SKIRT"},
    #DRESS
    "ë“œë ˆìŠ¤": {"ëŒ€ë¶„ë¥˜": "DRESS", "ì¤‘ë¶„ë¥˜": "ONE_PIECE"},
    #BAG
    "ë°±íŒ©": {"ëŒ€ë¶„ë¥˜": "BAG", "ì¤‘ë¶„ë¥˜": "BACKPACK"},
    "í† íŠ¸ë°±": {"ëŒ€ë¶„ë¥˜": "BAG", "ì¤‘ë¶„ë¥˜": "TOTE"},
    "í¬ë¡œìŠ¤ë°±": {"ëŒ€ë¶„ë¥˜": "BAG", "ì¤‘ë¶„ë¥˜": "CROSSBODY"},
    #SHOES
    "ìŠ¤ë‹ˆì»¤ì¦ˆ": {"ëŒ€ë¶„ë¥˜": "SHOES", "ì¤‘ë¶„ë¥˜": "SNEAKERS"},
    "ë¶€ì¸ ": {"ëŒ€ë¶„ë¥˜": "SHOES", "ì¤‘ë¶„ë¥˜": "BOOTS"},
    #HAT
    "ë³¼ìº¡": {"ëŒ€ë¶„ë¥˜": "HAT", "ì¤‘ë¶„ë¥˜": "CAP"},
    "ë¹„ë‹ˆ": {"ëŒ€ë¶„ë¥˜": "HAT", "ì¤‘ë¶„ë¥˜": "BEANIE"}

}

LIST_CONTAINER_SELECTORS = ["ul.prdList", "ul.prdList.grid4", ".prdList"]

# ===============================
# JS: ìƒí’ˆ ìŠ¤ëƒ…ìƒ· (URL/IMGëŠ” "imgë¥¼ ê°ì‹¸ëŠ” a"ì—ì„œë§Œ!)
# ===============================
JS_EXTRACT = r"""
() => {
  const results = [];

  const itemSelectors = [
    "ul.prdList > li[id^='anchorBoxId_']",
    "ul.prdList > li",
    ".prdList > li",
    "ul.prdList.grid4 > li",
  ];

  let items = [];
  for (const sel of itemSelectors) {
    const found = Array.from(document.querySelectorAll(sel));
    if (found.length) { items = found; break; }
  }

  const clean = (s) => (s || "").replace(/\s+/g, " ").trim();

  for (const item of items) {
    // âœ… ë§í¬ê°€ ì—¬ëŸ¬ ê°œë¼ì„œ, "imgë¥¼ í¬í•¨í•œ a"ë§Œ ì„ íƒ
    const thumbCandidates = Array.from(item.querySelectorAll("div.thumbnail a[href^='/product/']"));
    const thumbLink = thumbCandidates.find(a => a.querySelector("img")) || null;

    let href = thumbLink?.getAttribute("href") || "";
    if (href && !href.startsWith("http")) href = new URL(href, location.origin).href;

    const img = thumbLink?.querySelector("img") || item.querySelector("div.thumbnail img");
    let imgUrl =
      img?.getAttribute("src") ||
      img?.getAttribute("data-src") ||
      img?.getAttribute("data-original") ||
      img?.getAttribute("ec-data-src") ||
      "";

    if (imgUrl && imgUrl.startsWith("//")) imgUrl = location.protocol + imgUrl;
    if (imgUrl && imgUrl.startsWith("/")) imgUrl = new URL(imgUrl, location.origin).href;

    const name = clean(img?.getAttribute("alt")) || clean(item.querySelector(".description .name a")?.textContent);

    // ë¸Œëœë“œëŠ” ì‚¬ì´íŠ¸ë§ˆë‹¤ ë‹¤ë¥¼ ìˆ˜ ìˆì–´ fallback ì—¬ëŸ¬ ê°œ
    let rawBrand =
        item.querySelector(".description ul.hee_brand li a")?.textContent ||
        item.querySelector(".description .brand a")?.textContent ||
        item.querySelector(".description .brand")?.textContent ||
        "";

    let brand = clean(rawBrand)
        .replace(/^ë¸Œëœë“œ\s*[:ï¼š]?\s*/i, "")
        .replace(/^brand\s*[:ï¼š]?\s*/i, "");

    // âœ… ê°€ê²©/í• ì¸ìœ¨: ë¼ë²¨ì´ ì—†ì–´ì„œ description ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ %/ì› ì¶”ì¶œ
    const desc = item.querySelector(".description") || item;
    const text = desc.textContent || "";

    const discountMatch = text.match(/(\d{1,3})\s*%/);
    const discount = discountMatch ? discountMatch[1] : "";

    // ì› ë‹¨ìœ„ ìˆ«ì ì „ë¶€ ì¶”ì¶œ(2ê°œë©´ ì •ê°€/í• ì¸ê°€ë¡œ ë¶„ë¦¬ ê°€ëŠ¥)
    const priceMatches = Array.from(text.matchAll(/(\d[\d,]*)\s*ì›/g))
      .map(m => parseInt(m[1].replace(/,/g, ""), 10))
      .filter(n => Number.isFinite(n));

    // ì¼ë‹¨ ì›ë¬¸ ìˆ«ìë“¤ì„ ê·¸ëŒ€ë¡œ ë„˜ê¸°ê³ , íŒŒì´ì¬ì—ì„œ ì •ê°€/í• ì¸ê°€ íŒë‹¨ì„ ë” ì•ˆì „í•˜ê²Œ í•¨
    results.push({
      brand,
      name,
      href,
      imgUrl,
      discount,
      prices: priceMatches
    });
  }

  return results;
}
"""

# ===============================
# JS: í˜ì´ì§€ë„¤ì´ì…˜ ì •ë³´(ìµœëŒ€ í˜ì´ì§€/next ìœ ë¬´/í˜„ì¬ í˜ì´ì§€)
# ===============================
JS_PAGING_INFO = r"""
() => {
  const toNum = (v) => {
    const n = parseInt(String(v || "").trim(), 10);
    return Number.isFinite(n) ? n : null;
  };

  const pageFromHref = (href) => {
    try {
      const u = new URL(href, location.origin);
      const p = u.searchParams.get("page");
      return p ? toNum(p) : null;
    } catch(e) {
      return null;
    }
  };

  const pageLinks = Array.from(document.querySelectorAll("a[href*='page=']"));
  const pages = pageLinks
    .map(a => pageFromHref(a.getAttribute("href") || ""))
    .filter(n => n !== null);

  const maxPage = pages.length ? Math.max(...pages) : 1;

  const nextCandidates = Array.from(document.querySelectorAll(
    "a.next, a[rel='next'], .ec-base-paginate a.next, .paginate a.next"
  ));

  const isActiveNext = (a) => {
    if (!a) return false;
    const href = (a.getAttribute("href") || "").trim().toLowerCase();
    if (!href || href === "#" || href.startsWith("javascript")) return false;
    const cls = (a.getAttribute("class") || "").toLowerCase();
    if (cls.includes("disabled")) return false;
    return true;
  };

  const hasNext = nextCandidates.some(isActiveNext);

  let currentPage = null;
  const selected =
    document.querySelector(".paginate li.selected a, .ec-base-paginate li.selected a, .pagination .active a");
  if (selected) currentPage = toNum(selected.textContent);

  if (!currentPage) {
    const u = new URL(location.href);
    const p = u.searchParams.get("page");
    currentPage = p ? toNum(p) : 1;
  }

  return { currentPage: currentPage || 1, maxPage, hasNext };
}
"""

# ===============================
def build_page_url(base_url, page_num):
    parts = urlsplit(base_url)
    q = parse_qs(parts.query)
    q.pop("page", None)
    if page_num > 1:
        q["page"] = [str(page_num)]
    return urlunsplit((parts.scheme, parts.netloc, parts.path, urlencode(q, doseq=True), ""))

def normalize_url(u):
    p = urlsplit(u)
    return urlunsplit((p.scheme, p.netloc, p.path, "", ""))

# ===============================
def scrape():
    rows = []
    global_seen = set()

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=False, slow_mo=30)
        page = browser.new_page(viewport={"width": 1400, "height": 900})

        for category, base_url in CATEGORIES.items():
            print(f"\nğŸ“‚ {category}")
            page_num = 1
            no_new = 0

            while page_num <= MAX_PAGES_PER_CATEGORY:
                page.goto(build_page_url(base_url, page_num), wait_until="domcontentloaded")
                time.sleep(1)

                snapshot = page.evaluate(JS_EXTRACT)
                paging = page.evaluate(JS_PAGING_INFO)

                added = 0
                for it in snapshot:
                    href = normalize_url(it["href"])
                    if href in global_seen:
                        continue
                    global_seen.add(href)

                    prices = it["prices"]
                    discount = int(it["discount"]) if it["discount"] else None

                    if len(prices) >= 2:
                        original, sale = max(prices), min(prices)
                    elif len(prices) == 1:
                        sale = prices[0]
                        original = (
                            int(round(sale * 100 / (100 - discount), -1))
                            if discount else sale
                        )
                    else:
                        continue

                    rows.append({
                        "ëŒ€ë¶„ë¥˜": CATEGORY_MAP[category]["ëŒ€ë¶„ë¥˜"],
                        "ì¤‘ë¶„ë¥˜": CATEGORY_MAP[category]["ì¤‘ë¶„ë¥˜"],
                        "ì¹´í…Œê³ ë¦¬": category,
                        "ë¸Œëœë“œ": it["brand"],
                        "ìƒí’ˆëª…": it["name"],
                        "ì •ê°€": original,
                        "íŒë§¤ê°€": sale,
                        "í• ì¸ìœ¨(%)": discount or "-",
                        "ìƒí’ˆ URL": href,
                        "ì´ë¯¸ì§€ URL": it["imgUrl"],
                    })
                    added += 1

                print(f"  â†’ page {page_num}, ì‹ ê·œ {added}ê°œ")

                if added == 0:
                    no_new += 1
                    if no_new >= NO_NEW_PAGES_LIMIT:
                        break
                else:
                    no_new = 0

                if not paging["hasNext"] and page_num >= paging["maxPage"]:
                    break

                page_num += 1

        browser.close()

    # ===============================
    # ëŒ€ë¶„ë¥˜ë³„ CSV ì €ì¥ (í—¤ë” âŒ)
    # ===============================
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    grouped = {}
    for r in rows:
        grouped.setdefault(r["ëŒ€ë¶„ë¥˜"], []).append(r)

    for major, items in grouped.items():
        with open(os.path.join(OUTPUT_DIR, f"{major}.csv"), "w", newline="", encoding="utf-8-sig") as f:
            writer = csv.DictWriter(f, fieldnames=items[0].keys())
            writer.writerows(items)

        print(f"âœ… {major}.csv ì €ì¥ ({len(items)}ê°œ)")

# ===============================
if __name__ == "__main__":
    scrape()
