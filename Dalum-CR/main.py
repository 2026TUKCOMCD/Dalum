import os
import csv
import subprocess
import sys

# ===============================
# ê²½ë¡œ ì„¤ì •
# ===============================
BASE_DIR = os.path.dirname(os.path.abspath(__file__))

CRAWLERS_DIR = os.path.join(BASE_DIR, "crawlers")
OUTPUT_DIR = os.path.join(BASE_DIR, "output")
MERGED_DIR = os.path.join(BASE_DIR, "merged")
FINAL_DIR = os.path.join(BASE_DIR, "final")

# ===============================
# ì‹¤í–‰í•  í¬ë¡¤ëŸ¬ ëª©ë¡
# ===============================
CRAWLERS = [
    "musinsa.py",
    "musinsa_empty.py",
    "cm29.py",
    "fruitsfamily.py",
    # "kream.py",
]

SHOP_MALLS = [
    "musinsa",
    "musinsa_empty",
    "29cm",
    "fruitsfamily",
    # "kream",
]

CATEGORIES = [
    "OUTER",
    "TOP",
    "BOTTOM",
    "SHOES",
    "BAG",
    "ACC",
    "DRESS",
]

FINAL_HEADER = [
    "ì‡¼í•‘ëª°",
    "ëŒ€ë¶„ë¥˜",
    "ì¤‘ë¶„ë¥˜",
    "ì¹´í…Œê³ ë¦¬",
    "ë¸Œëœë“œ",
    "ìƒí’ˆëª…",
    "ì •ê°€",
    "íŒë§¤ê°€",
    "í• ì¸ìœ¨(%)",
    "ìƒí’ˆ URL",
    "ì´ë¯¸ì§€ URL",
]

# ===============================
# ë””ë ‰í† ë¦¬ ë³´ì¥
# ===============================
def ensure_dirs():
    os.makedirs(MERGED_DIR, exist_ok=True)
    os.makedirs(FINAL_DIR, exist_ok=True)

# ===============================
# í¬ë¡¤ëŸ¬ ì‹¤í–‰
# ===============================
def run_crawlers():
    print("\nğŸš€ [1/3] í¬ë¡¤ë§ ë‹¨ê³„ ì‹œì‘")

    for crawler in CRAWLERS:
        crawler_path = os.path.join(CRAWLERS_DIR, crawler)
        print(f"\nâ–¶ ì‹¤í–‰ ì¤‘: {crawler}")

        try:
            result = subprocess.run(
                [sys.executable, crawler_path],
                check=False
            )

            if result.returncode != 0:
                print(f"âš  í¬ë¡¤ëŸ¬ ì‹¤íŒ¨: {crawler} (continue)")
            else:
                print(f"âœ… ì™„ë£Œ: {crawler}")

        except Exception as e:
            print(f"âŒ ì‹¤í–‰ ì˜¤ë¥˜: {crawler} | {e}")

    print("\nğŸš€ í¬ë¡¤ë§ ë‹¨ê³„ ì¢…ë£Œ")

# ===============================
def read_csv_no_header(path):
    if not os.path.exists(path):
        return []

    rows = []
    with open(path, "r", encoding="utf-8-sig", newline="") as f:
        reader = csv.reader(f)
        for row in reader:
            if row:
                rows.append(row)
    return rows

# ===============================
# output â†’ merged
# ===============================
def merge_by_category():
    print("\nğŸ“¦ [2/3] 2ì°¨ ê²°ê³¼ë¬¼ ìƒì„± (output â†’ merged)")

    for category in CATEGORIES:
        merged_rows = []

        for mall in SHOP_MALLS:
            path = os.path.join(OUTPUT_DIR, mall, f"{category}.csv")
            rows = read_csv_no_header(path)

            for r in rows:
                merged_rows.append([mall] + r)

        if not merged_rows:
            print(f"âš  {category}: ë³‘í•© ë°ì´í„° ì—†ìŒ (skip)")
            continue

        merged_path = os.path.join(MERGED_DIR, f"{category}.csv")
        with open(merged_path, "w", newline="", encoding="utf-8-sig") as f:
            writer = csv.writer(f)
            writer.writerows(merged_rows)

        print(f"âœ… merged/{category}.csv ({len(merged_rows)}ê°œ)")

# ===============================
# merged â†’ final
# ===============================
def merge_all():
    print("\nâ­ [3/3] ìµœì¢… ê²°ê³¼ë¬¼ ìƒì„± (merged â†’ final)")

    final_rows = []

    for category in CATEGORIES:
        path = os.path.join(MERGED_DIR, f"{category}.csv")
        rows = read_csv_no_header(path)
        final_rows.extend(rows)

    if not final_rows:
        print("âŒ ìµœì¢… ë³‘í•© ë°ì´í„° ì—†ìŒ")
        return

    final_path = os.path.join(FINAL_DIR, "all_products.csv")
    with open(final_path, "w", newline="", encoding="utf-8-sig") as f:
        writer = csv.writer(f)
        writer.writerow(FINAL_HEADER)
        writer.writerows(final_rows)

    print(f"ğŸ‰ final/all_products.csv ìƒì„± ì™„ë£Œ ({len(final_rows)}ê°œ)")

# ===============================
def main():
    ensure_dirs()
    run_crawlers()
    merge_by_category()
    merge_all()

# ===============================
if __name__ == "__main__":
    main()
